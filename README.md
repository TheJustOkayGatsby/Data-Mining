This is a selection of exercises from the Data Mining Module. This was a main focal point of the degree course of study and expanded on the first half of the computational keystone: Machine Learning. Machine Learning exercises may be found in seperate repo.

Models used in this module:
1) Naive Bayes
2) SVC: Support Vector Classification
3) SVM: Support Vector Machine
4) PCA: Principal Component Analysis
5) UMAP: Uniform Manifold Approximation and Projection
6) Decision Trees, sort of
7) Random Forest
8) AdaBoost
9) Gradient Boosting
10) Logistic Regression
11) MLP: MultiLayer Perceptron
12) K Means
13) DB Scan

Topics covered within this module: 
1) Text Mining

   This converted unstructured text to a cleaned text which could be mined for tokens to make predictions with. Structured and unstructured.
   Using **BeautifulSoup**
   Using **Natural Language ToolKit(NLTK)**
   Running **classification**, **clustering** and **regression** analysis on featurized texts

  3) **Neural Nets**, in theory and in deployment
    - **MultiLayer Perceptron**
 
  4) **Clustering Analysis**
     - via PCA, Kmeans, DBScan
    
  5) Graph Mining
     - This was the most robust part of the module, and included pathfinding and centrality algorithms, all of which were solveed by hand prior to introducing code.
     - Taught methods:
       - **Dijkstra**'s
       - **Ford Fulkerson**
       - **Betweenness** Centrality
       - **Closeness** Centrality
       - **Degree** Centrality
